{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmhirwa/ML-Pipeline_Task1/blob/main/APIs_and_Web_scraping_Peer_Learning_Activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLD 1** APIs and Web scraping Peer Learning Activity"
      ],
      "metadata": {
        "id": "zGyTiyZZGA9c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ExVR4YYXb-O"
      },
      "source": [
        "Task 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu9LPULRUds_",
        "outputId": "23cceb85-561b-40c7-925b-ba32386fc10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CR90 corvette', 'Sentinel-class landing craft', 'Death Star', 'Executor', 'Rebel transport', 'Imperial shuttle', 'EF76 Nebulon-B escort frigate', 'Calamari Cruiser', 'Republic Cruiser', 'Droid control ship', 'J-type diplomatic barge', 'AA-9 Coruscant freighter', 'Republic Assault ship', 'Solar Sailer', 'Trade Federation cruiser', 'Theta-class T-2c shuttle', 'Republic attack cruiser']\n"
          ]
        }
      ],
      "source": [
        "#Florent\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"Code to return the list of ships\"\"\"\n",
        "\n",
        "import requests\n",
        "\n",
        "def availableShips(passengerCount):\n",
        "    \"\"\" List of ships\n",
        "\n",
        "    Arguments:\n",
        "        passengerCount (int): number of passengers\n",
        "    \"\"\"\n",
        "    res = requests.get('https://swapi-api.alx-tools.com/api/starships')\n",
        "\n",
        "    output = []\n",
        "    while res.status_code == 200:\n",
        "        res = res.json()\n",
        "        for ship in res['results']:\n",
        "            passengers = ship['passengers'].replace(',', '')\n",
        "            try:\n",
        "                if int(passengers) >= passengerCount:\n",
        "                    output.append(ship['name'])\n",
        "            except ValueError:\n",
        "                pass\n",
        "        if res['next']:\n",
        "            res = requests.get(res['next'])\n",
        "        else:\n",
        "            break\n",
        "    return output\n",
        "\n",
        "# Testing; For colab only\n",
        "# Get ships with at least 10 passengers\n",
        "ships = availableShips(10)\n",
        "print(ships)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ9y3k7VXeHd"
      },
      "source": [
        "Scrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgXfarCVXjCY",
        "outputId": "3ba72b68-ad6f-4e28-a93f-4c6485d0e745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ruSosK9Xm1i",
        "outputId": "64ef1c16-f212-425f-9c91-e17df2673151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraped Data:\n",
            "                Team Name  Year Wins Losses OT Losses  Win % Goals For (GF)  \\\n",
            "0           Boston Bruins  1990   44     24             0.55            299   \n",
            "1          Buffalo Sabres  1990   31     30            0.388            292   \n",
            "2          Calgary Flames  1990   46     26            0.575            344   \n",
            "3      Chicago Blackhawks  1990   49     23            0.613            284   \n",
            "4       Detroit Red Wings  1990   34     38            0.425            273   \n",
            "5         Edmonton Oilers  1990   37     37            0.463            272   \n",
            "6        Hartford Whalers  1990   31     38            0.388            238   \n",
            "7       Los Angeles Kings  1990   46     24            0.575            340   \n",
            "8   Minnesota North Stars  1990   27     39            0.338            256   \n",
            "9      Montreal Canadiens  1990   39     30            0.487            273   \n",
            "10      New Jersey Devils  1990   32     33              0.4            272   \n",
            "11     New York Islanders  1990   25     45            0.312            223   \n",
            "12       New York Rangers  1990   36     31             0.45            297   \n",
            "13    Philadelphia Flyers  1990   33     37            0.412            252   \n",
            "14    Pittsburgh Penguins  1990   41     33            0.512            342   \n",
            "15       Quebec Nordiques  1990   16     50              0.2            236   \n",
            "16        St. Louis Blues  1990   47     22            0.588            310   \n",
            "17    Toronto Maple Leafs  1990   23     46            0.287            241   \n",
            "18      Vancouver Canucks  1990   28     43             0.35            243   \n",
            "19    Washington Capitals  1990   37     36            0.463            258   \n",
            "20          Winnipeg Jets  1990   26     43            0.325            260   \n",
            "21          Boston Bruins  1991   36     32             0.45            270   \n",
            "22         Buffalo Sabres  1991   31     37            0.388            289   \n",
            "23         Calgary Flames  1991   31     37            0.388            296   \n",
            "24     Chicago Blackhawks  1991   36     29             0.45            257   \n",
            "\n",
            "   Goals Against (GA) + / -  \n",
            "0                 264    35  \n",
            "1                 278    14  \n",
            "2                 263    81  \n",
            "3                 211    73  \n",
            "4                 298   -25  \n",
            "5                 272     0  \n",
            "6                 276   -38  \n",
            "7                 254    86  \n",
            "8                 266   -10  \n",
            "9                 249    24  \n",
            "10                264     8  \n",
            "11                290   -67  \n",
            "12                265    32  \n",
            "13                267   -15  \n",
            "14                305    37  \n",
            "15                354  -118  \n",
            "16                250    60  \n",
            "17                318   -77  \n",
            "18                315   -72  \n",
            "19                258     0  \n",
            "20                288   -28  \n",
            "21                275    -5  \n",
            "22                299   -10  \n",
            "23                305    -9  \n",
            "24                236    21  \n"
          ]
        }
      ],
      "source": [
        "# Mohamed Yasin\n",
        "# import Libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL to scrape data from\n",
        "url = 'https://www.scrapethissite.com/pages/forms/'\n",
        "\n",
        "# Send a GET request to fetch the page content\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find the table containing data\n",
        "table = soup.find('table')\n",
        "\n",
        "# Extract headers\n",
        "headers = [header.text.strip() for header in table.find_all('th')]\n",
        "\n",
        "# Extract rows\n",
        "rows = []\n",
        "for row in table.find_all('tr')[1:]:\n",
        "    cols = row.find_all('td')\n",
        "    data = [col.text.strip() for col in cols]\n",
        "    rows.append(data)\n",
        "\n",
        "# Create a DataFrame using the headers and rows\n",
        "df = pd.DataFrame(rows, columns=headers)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('scraped_data.csv', index=False)\n",
        "\n",
        "# Display the DataFrame in the output\n",
        "print(\"Scraped Data:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t1esZ7yh2pS"
      },
      "source": [
        "Amazon Scrapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f874zFZ8kxzz"
      },
      "outputs": [],
      "source": [
        "# Florent: Amazon scrapping; Amazon blocks after repeated use;\n",
        "# Change headers and add other headers to play it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T8iI8uAX_et",
        "outputId": "2f218842-929d-4c09-dd88-56dde6bb707b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped Products:\n",
            "Product: Acer Aspire 3 A315-24P-R7VH Slim Laptop | 15.6\" Full HD IPS Display | AMD Ryzen 3 7320U Quad-Core Processor | AMD Radeon Graphics | 8GB LPDDR5 | 128GB NVMe SSD | Wi-Fi 6 | Windows 11 Home in S Mode, Image saved at: product_images/laptops/Acer_Aspire_3_A315-24P-R7VH_Sl.jpg\n",
            "Product: HP Newest 255 G10 Laptop for Home or Work, 16GB RAM, 1TB SSD, 15.6\" Full HD, Ryzen 3 7330U (Beat Intel i5-1135G7), Ethernet Port, HDMI, USB-C, Windows 11 Pro, Business and Fun Ready (2024), Image saved at: product_images/laptops/HP_Newest_255_G10_Laptop_for_H.jpg\n",
            "Product: Acer Aspire Go 15 Slim Laptop | 15.6\" Full HD IPS 1080P Display | Intel Core i3-N305| Intel UHD Graphics | 8GB LPDDR5 | 128GB HD | Wi-Fi 6 | AI PC | Windows 11 Home in S Mode | AG15-31P-3947, Image saved at: product_images/laptops/Acer_Aspire_Go_15_Slim_Laptop_.jpg\n",
            "Product: HP Newest 14\" Ultral Light Laptop for Students and Business, Intel Quad-Core N4120, 8GB RAM, 192GB Storage(64GB eMMC+128GB Micro SD), 1 Year Office 365, Webcam, HDMI, WiFi, USB-A&C, Win 11 S, Image saved at: product_images/laptops/HP_Newest_14\"_Ultral_Light_Lap.jpg\n",
            "Product: HP Portable Laptop, Student and Business, 14\" HD Display, Intel Quad-Core N4120, 8GB DDR4 RAM, 64GB eMMC, 1 Year Office 365, Webcam, RJ-45, HDMI, Wi-Fi, Windows 11 Home, Silver, Image saved at: product_images/laptops/HP_Portable_Laptop,_Student_an.jpg\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# Create a directory to save images\n",
        "os.makedirs('product_images', exist_ok=True)\n",
        "os.makedirs('product_images/laptops', exist_ok=True)\n",
        "\n",
        "# Function to scrape products\n",
        "def scrape_products(search_query):\n",
        "    # Replace spaces with '+' for the search query\n",
        "    search_query = search_query.replace(' ', '+')\n",
        "    url = f'https://www.amazon.com/s?k={search_query}'\n",
        "\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0',\n",
        "        'Accept-Language': 'en-US, en;q=0.9',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
        "        'Referer': 'https://www.amazon.com/',\n",
        "    }\n",
        "\n",
        "    # Send a GET request to fetch the page content\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    products = []\n",
        "    count = 0\n",
        "\n",
        "    # Loop through search results and extract product data\n",
        "    for product in soup.find_all('div', {'data-component-type': 's-search-result'}):\n",
        "        # Extract product name\n",
        "        name = product.h2.text.strip()\n",
        "\n",
        "        # Extract image URL\n",
        "        image_tag = product.find('img', {'class': 's-image'})\n",
        "        image_url = image_tag['src'] if image_tag else None\n",
        "\n",
        "        if name and image_url and count < 5:\n",
        "            # Save image locally\n",
        "            image_response = requests.get(image_url)\n",
        "            image_path = f'product_images/laptops/{name[:30].replace(\" \", \"_\")}.jpg'\n",
        "            with open(image_path, 'wb') as f:\n",
        "                f.write(image_response.content)\n",
        "\n",
        "            products.append((name, image_path))\n",
        "            count += 1\n",
        "\n",
        "    return products\n",
        "\n",
        "# Searching for \"cookies\"\n",
        "products = scrape_products(\"laptops\")\n",
        "\n",
        "# Display product names and image paths\n",
        "print(\"Scraped Products:\")\n",
        "for product_name, image_path in products:\n",
        "    print(f'Product: {product_name}, Image saved at: {image_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFkGU0mbv0Zz"
      },
      "outputs": [],
      "source": [
        "os.makedirs('product_images/halloween', exist_ok=True) # additional categories to go to separate directories; example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXuihhuboVIO",
        "outputId": "12d01e20-3917-4c17-b45e-0c5f17ec4a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped Products:\n",
            "Product: Halloween Bulk Assorted Fruit Candy - Starburst, Skittles, Gummy Life Savers, Air Heads, Jolly Rancher, Sour Punch, Haribo Gold-Bears, Gummy Bears & Twizzlers (32 Oz Variety Pack), Image saved at: product_images/halloween/Halloween_Bulk_Assorted_Fruit_.jpg\n",
            "Product: Floating Candles with Wand, Halloween Decoration 20 PCs Magic Hanging Candles, Flickering Warm Light Flameless Floating LED Candle with Wand Remote, Battery Operated Taper Candle Set for Theme Party, Image saved at: product_images/halloween/Floating_Candles_with_Wand,_Ha.jpg\n",
            "Product: Ring Pop Halloween Bulk Variety Candy - 50 Ct Individually Wrapped Lollipops w/ Assorted Flavors - Fun Candy For Party Favors, Halloween Parties, Trick or Treat Goodie Bags, Bachelorette Parties, Image saved at: product_images/halloween/Ring_Pop_Halloween_Bulk_Variet.jpg\n",
            "Product: JOYIN Halloween Outdoor Decorations Hairy Spider, Scary Giant Spider Fake Large Props for Yard Party Decor, Black (Standing Height is 15 inches), Image saved at: product_images/halloween/JOYIN_Halloween_Outdoor_Decora.jpg\n",
            "Product: JOYIN 144 Pcs Glow Sticks Bulk 8\" Bracelets Necklaces, Glow in the Dark Neon, Easter, Football,Halloween Party Supplies Pack, Image saved at: product_images/halloween/JOYIN_144_Pcs_Glow_Sticks_Bulk.jpg\n"
          ]
        }
      ],
      "source": [
        "# Mohamed Yasin\n",
        "\n",
        "# import Libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# Create a directory to save images\n",
        "os.makedirs('product_images/halloween', exist_ok=True)\n",
        "\n",
        "# Function to scrape products\n",
        "def scrape_products(search_query):\n",
        "    # Replace spaces with '+' for the search query\n",
        "    search_query = search_query.replace(' ', '+')\n",
        "    url = f'https://www.amazon.com/s?k={search_query}'\n",
        "\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
        "        'Accept-Language': 'en-US, en;q=0.9',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
        "        'Referer': 'https://www.amazon.com/',\n",
        "    }\n",
        "\n",
        "    # Send a GET request to fetch the page content\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    products = []\n",
        "    count = 0\n",
        "\n",
        "    # Loop through search results and extract product data\n",
        "    for product in soup.find_all('div', {'data-component-type': 's-search-result'}):\n",
        "        # Extract product name\n",
        "        name = product.h2.text.strip()\n",
        "\n",
        "        # Extract image URL\n",
        "        image_tag = product.find('img', {'class': 's-image'})\n",
        "        image_url = image_tag['src'] if image_tag else None\n",
        "\n",
        "        if name and image_url and count < 5:\n",
        "            # Save image locally\n",
        "            image_response = requests.get(image_url)\n",
        "            image_path = f'product_images/halloween/{name[:30].replace(\" \", \"_\")}.jpg'\n",
        "            with open(image_path, 'wb') as f:\n",
        "                f.write(image_response.content)\n",
        "\n",
        "            products.append((name, image_path))\n",
        "            count += 1\n",
        "\n",
        "    return products\n",
        "\n",
        "# Searching for \"halloween\"\n",
        "products = scrape_products(\"halloween\")\n",
        "\n",
        "# Display product names and image paths\n",
        "print(\"Scraped Products:\")\n",
        "for product_name, image_path in products:\n",
        "    print(f'Product: {product_name}, Image saved at: {image_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ousgJl_Ap7G8",
        "outputId": "7d2c4649-265b-4a10-bd28-9ee599aa6f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped Products:\n",
            "Product: JOYIN 3 Pack Monster Truck Toy - Motion Activated Light-Up Cars for Toddlers - Monster Treads Lightning Wheels - Baby Toy Press & Go Cars for Boys Girls, Image saved at: product_images/toys/JOYIN_3_Pack_Monster_Truck_Toy.jpg\n",
            "Product: LCD Writing Tablet for Kids, Colorful Toddlers Toys Drawing Board, Educational Kid Toys, Doodle Pad Dinosaur Toys for 2 3 4 5 6 7 8 Year Old Boys Girls Birthday Party Christmas Gifts,8.5inch, Image saved at: product_images/toys/LCD_Writing_Tablet_for_Kids,_C.jpg\n",
            "Product: PicassoTiles Magnetic Tiles 60pcs Kids Toys Classroom Sensory Toy for Toddlers STEM Learning Building Blocks, Montessori Pretend Play Magnet Tile Construction Stacking Block Boys Girls Ages 3+ PT60, Image saved at: product_images/toys/PicassoTiles_Magnetic_Tiles_60.jpg\n",
            "Product: Gionlion Friendship Bracelet Kit Concert Bracelets Merch, 5200 Pcs Clay Beads Bracelet Making Kit for Beginner, DIY Arts and Crafts Teen Girl Gifts Toys for Ages 6-13, Image saved at: product_images/toys/Gionlion_Friendship_Bracelet_K.jpg\n",
            "Product: Transformers Toys Heroic Optimus Prime Action Figure - Timeless Large-Scale Figure, Changes into Toy Truck - Toys for Kids 6 and Up, 11-inch (Amazon Exclusive), Image saved at: product_images/toys/Transformers_Toys_Heroic_Optim.jpg\n"
          ]
        }
      ],
      "source": [
        "# Mohamed Yasin\n",
        "\n",
        "# import Libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# Create a directory to save images\n",
        "os.makedirs('product_images/toys', exist_ok=True)\n",
        "\n",
        "# Function to scrape products\n",
        "def scrape_products(search_query):\n",
        "    # Replace spaces with '+' for the search query\n",
        "    search_query = search_query.replace(' ', '+')\n",
        "    url = f'https://www.amazon.com/s?k={search_query}'\n",
        "\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
        "        'Accept-Language': 'en-US, en;q=0.9',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
        "        'Referer': 'https://www.amazon.com/',\n",
        "    }\n",
        "\n",
        "    # Send a GET request to fetch the page content\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    products = []\n",
        "    count = 0\n",
        "\n",
        "    # Loop through search results and extract product data\n",
        "    for product in soup.find_all('div', {'data-component-type': 's-search-result'}):\n",
        "        # Extract product name\n",
        "        name = product.h2.text.strip()\n",
        "\n",
        "        # Extract image URL\n",
        "        image_tag = product.find('img', {'class': 's-image'})\n",
        "        image_url = image_tag['src'] if image_tag else None\n",
        "\n",
        "        if name and image_url and count < 5:\n",
        "            # Save image locally\n",
        "            image_response = requests.get(image_url)\n",
        "            image_path = f'product_images/toys/{name[:30].replace(\" \", \"_\")}.jpg'\n",
        "            with open(image_path, 'wb') as f:\n",
        "                f.write(image_response.content)\n",
        "\n",
        "            products.append((name, image_path))\n",
        "            count += 1\n",
        "\n",
        "    return products\n",
        "\n",
        "# Searching for \"toys\"\n",
        "products = scrape_products(\"toys\")\n",
        "\n",
        "# Display product names and image paths\n",
        "print(\"Scraped Products:\")\n",
        "for product_name, image_path in products:\n",
        "    print(f'Product: {product_name}, Image saved at: {image_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPfiE4k1rTEH",
        "outputId": "5c8c9f73-5aec-44e0-8170-88bca776c586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product: Sullivans White Ceramic Vase Set, Farmhouse Decor, Home Decorative Vase, Vases For Your Kitchen, Bedroom, Office, Living Room, Bathroom, & Shelf Centerpiece Table Decorations (CM2333), Image saved at: product_images/decor/Sullivans_White_Cera.jpg\n",
            "Product: Rossetta Star Projector, Galaxy Projector for Bedroom, LED Night Light Aurora Projector with Bluetooth Speaker, White Noise, Timer and Remote, Room Decor, Gifts for Kids, Adults, Christmas, Birthday, Image saved at: product_images/decor/Rossetta_Star_Projec.jpg\n",
            "Product: Crystal Tree of Life 7 Chakra Healing Crystal Trees for Home Decor, Office Desk Decor, Living Room Decor, Handmade Bonsai Trees for Positive Energy, Money, Good Luck Birthday Gifts for Women, Mom, Image saved at: product_images/decor/Crystal_Tree_of_Life.jpg\n",
            "Product: LEGO Icons Dried Flower Centerpiece, Botanical Collection Crafts Set for Adults, Artificial Flowers with Rose and Gerbera, Table or Wall Decoration, Home Décor, 10314, Image saved at: product_images/decor/LEGO_Icons_Dried_Flo.jpg\n",
            "Product: Dosmix Retro Bluetooth Speaker, Vintage Decor, Mini Wireless Bluetooth Speaker, Cute Old Fashion Style for Kitchen Desk Bedroom Office Party Outdoor Accessories for iPhone Android (Green), Image saved at: product_images/decor/Dosmix_Retro_Bluetoo.jpg\n"
          ]
        }
      ],
      "source": [
        "# Pierrette U\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Create a directory to save product images\n",
        "os.makedirs('product_images/decor', exist_ok=True)\n",
        "\n",
        "# Function to scrape products from Amazon search results\n",
        "def scrape_amazon_products(search_query):\n",
        "    \"\"\"\n",
        "    Scrapes Amazon search results for a given search query.\n",
        "\n",
        "    Arguments:\n",
        "        search_query (str): The product search term to query on Amazon.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of product titles and image file paths.\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36',\n",
        "        'Accept-Language': 'en-US,en;q=0.9',\n",
        "        'Accept-Encoding': 'gzip, deflate, br',\n",
        "        'Referer': 'https://www.amazon.com/',\n",
        "        'Connection': 'keep-alive'\n",
        "    }\n",
        "\n",
        "    # Replace spaces with '+' for the search URL\n",
        "    url = f\"https://www.amazon.com/s?k={search_query.replace(' ', '+')}\"\n",
        "\n",
        "    # Send a GET request with headers to avoid blocking\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Parse the response content with BeautifulSoup\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all product containers\n",
        "        products = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
        "\n",
        "        product_details = []  # List to store product titles and image paths\n",
        "\n",
        "        # Iterate over the products\n",
        "        for product in products[:5]:  # Limit to 5 products\n",
        "            try:\n",
        "                # Extract product title\n",
        "                title = product.h2.text.strip()\n",
        "\n",
        "                # Extract image URL\n",
        "                image_tag = product.find('img', {'class': 's-image'})\n",
        "                image_url = image_tag['src']\n",
        "\n",
        "                # Save the image locally\n",
        "                img_data = requests.get(image_url).content\n",
        "                img_filename = f\"product_images/decor/{title[:20].replace(' ', '_')}.jpg\"  # Shorten title for filename\n",
        "                with open(img_filename, 'wb') as handler:\n",
        "                    handler.write(img_data)\n",
        "\n",
        "                # Append product details\n",
        "                product_details.append({\n",
        "                    'title': title,\n",
        "                    'image': img_filename\n",
        "                })\n",
        "\n",
        "                # Add a random delay between requests to avoid getting blocked\n",
        "                time.sleep(random.uniform(1, 5))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing product: {e}\")\n",
        "                continue\n",
        "\n",
        "        return product_details\n",
        "    elif response.status_code == 503:\n",
        "        print(f\"Service unavailable (503), trying again after a short delay...\")\n",
        "        time.sleep(10)  # Wait and retry after 10 seconds\n",
        "        return scrape_amazon_products(search_query)  # Recursive retry\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to retrieve Amazon page, status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "# Example: Scrape for \"decor\"\n",
        "products = scrape_amazon_products('Decor')\n",
        "\n",
        "# Print product details\n",
        "for product in products:\n",
        "    print(f\"Product: {product['title']}, Image saved at: {product['image']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aime\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Create a directory to save product images\n",
        "os.makedirs('product_images/watches', exist_ok=True)\n",
        "\n",
        "# Function to scrape products from Amazon search results\n",
        "def scrape_amazon_products(search_query):\n",
        "    \"\"\"\n",
        "    Scrapes Amazon search results for a given search query.\n",
        "\n",
        "    Arguments:\n",
        "        search_query (str): The product search term to query on Amazon.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of product titles and image file paths.\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36',\n",
        "        'Accept-Language': 'en-US,en;q=0.9',\n",
        "        'Accept-Encoding': 'gzip, deflate, br',\n",
        "        'Referer': 'https://www.amazon.com/',\n",
        "        'Connection': 'keep-alive'\n",
        "    }\n",
        "\n",
        "    # Replace spaces with '+' for the search URL\n",
        "    url = f\"https://www.amazon.com/s?k={search_query.replace(' ', '+')}\"\n",
        "\n",
        "    # Send a GET request with headers to avoid blocking\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Parse the response content with BeautifulSoup\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all product containers\n",
        "        products = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
        "\n",
        "        product_details = []  # List to store product titles and image paths\n",
        "\n",
        "        # Iterate over the products\n",
        "        for product in products[:5]:  # Limit to 5 products\n",
        "            try:\n",
        "                # Extract product title\n",
        "                title = product.h2.text.strip()\n",
        "\n",
        "                # Extract image URL\n",
        "                image_tag = product.find('img', {'class': 's-image'})\n",
        "                image_url = image_tag['src']\n",
        "\n",
        "                # Save the image locally\n",
        "                img_data = requests.get(image_url).content\n",
        "                img_filename = f\"product_images/watches/{title[:20].replace(' ', '_')}.jpg\"  # Shorten title for filename\n",
        "                with open(img_filename, 'wb') as handler:\n",
        "                    handler.write(img_data)\n",
        "\n",
        "                # Append product details\n",
        "                product_details.append({\n",
        "                    'title': title,\n",
        "                    'image': img_filename\n",
        "                })\n",
        "\n",
        "                # Add a random delay between requests to avoid getting blocked\n",
        "                time.sleep(random.uniform(1, 5))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing product: {e}\")\n",
        "                continue\n",
        "\n",
        "        return product_details\n",
        "    elif response.status_code == 503:\n",
        "        print(f\"Service unavailable (503), trying again after a short delay...\")\n",
        "        time.sleep(10)  # Wait and retry after 10 seconds\n",
        "        return scrape_amazon_products(search_query)  # Recursive retry\n",
        "\n",
        "    else:\n",
        "        print(f\"Failed to retrieve Amazon page, status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "# Example: Scrape for \"watches\"\n",
        "products = scrape_amazon_products('watches')\n",
        "\n",
        "# Print product details\n",
        "for product in products:\n",
        "    print(f\"Product: {product['title']}, Image saved at: {product['image']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUeVxcboID3M",
        "outputId": "49090d7d-4bd8-4e72-fc7f-77d060b640df"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product: Casio, Image saved at: product_images/watches/Casio.jpg\n",
            "Product: Apple, Image saved at: product_images/watches/Apple.jpg\n",
            "Product: SAMSUNG, Image saved at: product_images/watches/SAMSUNG.jpg\n",
            "Product: Casio, Image saved at: product_images/watches/Casio.jpg\n",
            "Product: Casio, Image saved at: product_images/watches/Casio.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zip Files"
      ],
      "metadata": {
        "id": "L3IaHvY0D-zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r product_images.zip product_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxumkGUVD-RQ",
        "outputId": "d132a350-a56b-440f-c5d4-0b075b6e2d3e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: product_images/ (stored 0%)\n",
            "  adding: product_images/laptops/ (stored 0%)\n",
            "  adding: product_images/laptops/HP_Newest_255_G10_Laptop_for_H.jpg (deflated 1%)\n",
            "  adding: product_images/laptops/HP_Portable_Laptop,_Student_an.jpg (deflated 3%)\n",
            "  adding: product_images/laptops/Acer_Aspire_3_A315-24P-R7VH_Sl.jpg (deflated 3%)\n",
            "  adding: product_images/laptops/Acer_Aspire_Go_15_Slim_Laptop_.jpg (deflated 3%)\n",
            "  adding: product_images/laptops/HP_Newest_14\"_Ultral_Light_Lap.jpg (deflated 3%)\n",
            "  adding: product_images/halloween/ (stored 0%)\n",
            "  adding: product_images/halloween/JOYIN_Halloween_Outdoor_Decora.jpg (stored 0%)\n",
            "  adding: product_images/halloween/Halloween_Bulk_Assorted_Fruit_.jpg (deflated 0%)\n",
            "  adding: product_images/halloween/Ring_Pop_Halloween_Bulk_Variet.jpg (deflated 0%)\n",
            "  adding: product_images/halloween/JOYIN_144_Pcs_Glow_Sticks_Bulk.jpg (deflated 0%)\n",
            "  adding: product_images/halloween/Floating_Candles_with_Wand,_Ha.jpg (stored 0%)\n",
            "  adding: product_images/watches/ (stored 0%)\n",
            "  adding: product_images/watches/Casio.jpg (deflated 1%)\n",
            "  adding: product_images/watches/Apple.jpg (deflated 1%)\n",
            "  adding: product_images/watches/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: product_images/watches/SAMSUNG.jpg (deflated 1%)\n",
            "  adding: product_images/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: product_images/decor/ (stored 0%)\n",
            "  adding: product_images/decor/Dosmix_Retro_Bluetoo.jpg (deflated 4%)\n",
            "  adding: product_images/decor/LEGO_Icons_Dried_Flo.jpg (deflated 0%)\n",
            "  adding: product_images/decor/Rossetta_Star_Projec.jpg (deflated 0%)\n",
            "  adding: product_images/decor/Crystal_Tree_of_Life.jpg (deflated 0%)\n",
            "  adding: product_images/decor/Sullivans_White_Cera.jpg (deflated 2%)\n",
            "  adding: product_images/toys/ (stored 0%)\n",
            "  adding: product_images/toys/PicassoTiles_Magnetic_Tiles_60.jpg (deflated 0%)\n",
            "  adding: product_images/toys/Gionlion_Friendship_Bracelet_K.jpg (deflated 0%)\n",
            "  adding: product_images/toys/JOYIN_3_Pack_Monster_Truck_Toy.jpg (deflated 0%)\n",
            "  adding: product_images/toys/LCD_Writing_Tablet_for_Kids,_C.jpg (deflated 1%)\n",
            "  adding: product_images/toys/Transformers_Toys_Heroic_Optim.jpg (deflated 1%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"product_images.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "m2EvcXWMEOEM",
        "outputId": "6c934188-5d8f-48dc-8514-261529934016"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_006d0bed-ee50-4eec-afdf-2a4d47e84f4e\", \"product_images.zip\", 450172)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}